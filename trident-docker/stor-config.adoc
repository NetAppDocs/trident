---
sidebar: sidebar
permalink: trident-docker/stor-config.html
keywords: deploy, trident, docker, trident for docker, nfs, iscsi, protcol, nfs protocol, iscsi protocol, configure host, host config, storage config, options, variables, ontap, element, cvs on gcp, anf, azure netapp files, google cloud platform, storage pool labels, storage pool, cvs, cvs-performance, service type, service level, cloud volumes service, cloud volumes
summary: See the configuration options available for your Astra Trident configurations.
---

= Storage configuration options
:hardbreaks:
:icons: font
:imagesdir: ../media/

[.lead]
See the configuration options available for your Astra Trident configurations.

== Global configuration options

These configuration options apply to all Astra Trident configurations, regardless of the storage platform being used.

[%header,cols=3*]
|===
|Option
|Description
|Example

|`version`
a|Config file version number
a|1

|`storageDriverName`
a|Name of storage driver
a|`ontap-nas`, `ontap-san`, `ontap-nas-economy`,
`ontap-nas-flexgroup`, `solidfire-san`, `azure-netapp-files`, or `gcp-cvs`

|`storagePrefix`
a|Optional prefix for volume names. Default: “netappdvp_”.
a|staging_

|`limitVolumeSize`
a|Optional restriction on volume sizes. Default: “” (not enforced)
a|10g

|===

TIP: Do not use `storagePrefix` (including the default) for Element backends. By default, the `solidfire-san` driver will ignore this setting and not use a prefix. We recommend using either a specific tenantID for Docker volume mapping or using the attribute data which is populated with the Docker version, driver info, and raw name from Docker in cases where any name munging may have been used.

Default options are available to avoid having to specify them on every volume you create. The `size` option is available for all the controller types. See the ONTAP configuration section for an example of how to set the default volume size.

[%header,cols=3*]
|===
|Option
|Description
|Example

|`size`
a|Optional default size for new volumes. Default: “1G”
a|10G

|===

== ONTAP configuration

In addition to the global configuration values above, when using ONTAP, the following top-level options are available.

[%header,cols=3*]
|===
|Option
|Description
|Example

|`managementLIF`
a|IP address of ONTAP management LIF. You can specify a fully-qualified domain name (FQDN).
a|10.0.0.1

|`dataLIF`
a|IP address of protocol LIF; will be derived if not specified. For the `ontap-nas` drivers *only*, you can specify an FQDN, in which case the FQDN will be used for the NFS mount operations. For the `ontap-san` drivers, the default is to use all data LIF IPs from the SVM and to use iSCSI multipath. Specifying an IP address for `dataLIF` for the `ontap-san` drivers forces the driver to disable multipath and use only the specified address.
a|10.0.0.2

|`svm`
a|Storage virtual machine to use (required, if management LIF is a cluster LIF)
a|svm_nfs

|`username`
a|Username to connect to the storage device
a|vsadmin

|`password`
a|Password to connect to the storage device
a|secret

|`aggregate`
a|Aggregate for provisioning (optional; if set, must be assigned to the SVM). For the `ontap-nas-flexgroup` driver, this option is ignored. All aggregates assigned to the SVM are used to provision a FlexGroup Volume.
a|aggr1

|`limitAggregateUsage`
a|Optional, fail provisioning if usage is above this percentage
a|75%

|`nfsMountOptions`
a| Fine grained control of NFS mount options; defaults to “-o nfsvers=3”. *Available only for the `ontap-nas` and `ontap-nas-economy` drivers*. https://www.netapp.com/pdf.html?item=/media/10720-tr-4067.pdf[See NFS host configuration information here^].
a|-o nfsvers=4

|`igroupName`
a|The igroup used by the plugin; defaults to “netappdvp”. *Available only for the `ontap-san`driver*.
a|myigroup

|`limitVolumeSize`
a|Maximum requestable volume size and qtree parent volume size. *For the `ontap-nas-economy` driver, this option additionally limits the size of the FlexVols that it creates*.
a|300g

|`qtreesPerFlexvol`
a|Maximum qtrees per FlexVol, must be in range [50, 300], default is 200.  *For the `ontap-nas-economy` driver, this option allows customizing the maximum number of qtrees per FlexVol*.
a|300

|===

Default options are available to avoid having to specify them on every volume you create:

[%header,cols=3*]
|===
|Option
|Description
|Example

|`spaceReserve`
a|Space reservation mode; “none” (thin provisioned) or “volume” (thick)
a|none

|`snapshotPolicy`
a|Snapshot policy to use, default is “none”
a|none

|`snapshotReserve`
a|Snapshot reserve percentage, default is “” to accept ONTAP’s default
a|10

|`splitOnClone`
a|Split a clone from its parent upon creation, defaults to “false”
a|false

|`encryption`
a|Enables NetApp Volume Encryption (NVE) on the new volume; defaults to `false`. NVE must be licensed and enabled on the cluster to use this option. 

If NAE is enabled on the backend, any volume provisioned in Astra Trident will be NAE enabled. 

For more information, refer to: link:../trident-reco/security-reco.html[How Astra Trident works with NVE and NAE].
a|true

|`unixPermissions`
a|NAS option for provisioned NFS volumes, defaults to “777”
a|777

|`snapshotDir`
a|NAS option for access to the `.snapshot` directory, defaults to “false”
a|true

|`exportPolicy`
a|NAS option for the NFS export policy to use, defaults to “default”
a|default

|`securityStyle`
a|NAS option for access to the provisioned NFS volume, defaults to “unix”
a|mixed

|`fileSystemType`
a|SAN option to select the file system type, defaults to “ext4”
a|xfs

|`tieringPolicy`
a|Tiering policy to use, default is “none”; “snapshot-only” for pre-ONTAP 9.5 SVM-DR configuration
a|none

|===

=== Scaling options

The `ontap-nas` and `ontap-san` drivers create an ONTAP FlexVol for each Docker volume. ONTAP supports up to 1000 FlexVols per cluster node with a cluster maximum of 12,000 FlexVols. If your Docker volume requirements fit within that limitation, the `ontap-nas` driver is the preferred NAS solution due to the additional features offered by FlexVols, such as Docker-volume-granular snapshots and cloning.

If you need more Docker volumes than can be accommodated by the FlexVol limits, choose the `ontap-nas-economy` or the `ontap-san-economy` driver.

The `ontap-nas-economy` driver creates Docker volumes as ONTAP Qtrees within a pool of automatically managed FlexVols. Qtrees offer far greater scaling, up to 100,000 per cluster node and 2,400,000 per cluster, at the expense of some features. The `ontap-nas-economy` driver does not support Docker-volume-granular snapshots or cloning.

NOTE: The `ontap-nas-economy` driver is not currently supported in Docker Swarm, because Swarm does not orchestrate volume creation across multiple nodes.

The `ontap-san-economy` driver creates Docker volumes as ONTAP LUNs within a shared pool of automatically managed FlexVols. This way, each FlexVol is not restricted to only one LUN and it offers better scalability for SAN workloads. Depending on the storage array, ONTAP supports up to 16384 LUNs per cluster. Because the volumes are LUNs underneath, this driver supports Docker-volume-granular snapshots and cloning.

Choose the `ontap-nas-flexgroup` driver to increase parallelism to a single volume that can grow into the petabyte range with billions of files. Some ideal use cases for FlexGroups include AI/ML/DL, big data and analytics, software builds, streaming, file repositories, and so on. Trident uses all aggregates assigned to an SVM when provisioning a FlexGroup Volume. FlexGroup support in Trident also has the following considerations:

* Requires ONTAP version 9.2 or greater.
* As of this writing, FlexGroups only support NFS v3.
* Recommended to enable the 64-bit NFSv3 identifiers for the SVM.
* The minimum recommended FlexGroup size is 100GB.
* Cloning is not supported for FlexGroup Volumes.

For information about FlexGroups and workloads that are appropriate for FlexGroups see the https://www.netapp.com/pdf.html?item=/media/12385-tr4571pdf.pdf[NetApp FlexGroup Volume Best Practices and Implementation Guide^].

To get advanced features and huge scale in the same environment, you can run multiple instances of the Docker Volume Plugin, with one using `ontap-nas` and another using `ontap-nas-economy`.

=== Example ONTAP configuration files

*NFS example for `ontap-nas` driver*

----
{
    "version": 1,
    "storageDriverName": "ontap-nas",
    "managementLIF": "10.0.0.1",
    "dataLIF": "10.0.0.2",
    "svm": "svm_nfs",
    "username": "vsadmin",
    "password": "secret",
    "aggregate": "aggr1",
    "defaults": {
      "size": "10G",
      "spaceReserve": "none",
      "exportPolicy": "default"
    }
}
----

*NFS example for `ontap-nas-flexgroup` driver*

----
{
    "version": 1,
    "storageDriverName": "ontap-nas-flexgroup",
    "managementLIF": "10.0.0.1",
    "dataLIF": "10.0.0.2",
    "svm": "svm_nfs",
    "username": "vsadmin",
    "password": "secret",
    "defaults": {
      "size": "100G",
      "spaceReserve": "none",
      "exportPolicy": "default"
    }
}
----

*NFS example for `ontap-nas-economy` driver*

----
{
    "version": 1,
    "storageDriverName": "ontap-nas-economy",
    "managementLIF": "10.0.0.1",
    "dataLIF": "10.0.0.2",
    "svm": "svm_nfs",
    "username": "vsadmin",
    "password": "secret",
    "aggregate": "aggr1"
}
----

*iSCSI example for `ontap-san` driver*

----
{
    "version": 1,
    "storageDriverName": "ontap-san",
    "managementLIF": "10.0.0.1",
    "dataLIF": "10.0.0.3",
    "svm": "svm_iscsi",
    "username": "vsadmin",
    "password": "secret",
    "aggregate": "aggr1",
    "igroupName": "myigroup"
}
----

*NFS example for `ontap-san-economy` driver*

----
{
    "version": 1,
    "storageDriverName": "ontap-san-economy",
    "managementLIF": "10.0.0.1",
    "dataLIF": "10.0.0.3",
    "svm": "svm_iscsi_eco",
    "username": "vsadmin",
    "password": "secret",
    "aggregate": "aggr1",
    "igroupName": "myigroup"
}
----

== Element software configuration

In addition to the global configuration values, when using Element software (NetApp HCI/SolidFire), these options are available.

[%header,cols=3*]
|===
|Option
|Description
|Example

|`Endpoint`
a|\https://<login>:<password>@<mvip>/json-rpc/<element-version>
a|\https://admin:admin@192.168.160.3/json-rpc/8.0

|`SVIP`
a|iSCSI IP address and port
a|10.0.0.7:3260

|`TenantName`
a|SolidFireF Tenant to use (created if not found)
a|“docker”

|`InitiatorIFace`
a|Specify interface when restricting iSCSI traffic to non-default interface
a|“default”

|`Types`
a|QoS specifications
a|See example below

|`LegacyNamePrefix`
a|Prefix for upgraded Trident installs. If you used a version of Trident prior to 1.3.2 and perform an upgrade with existing volumes, you’ll need to set this value to access your old volumes that were mapped via the volume-name method.
a|“netappdvp-”

|===

The `solidfire-san` driver does not support Docker Swarm.

=== Example Element software configuration file

----
{
    "version": 1,
    "storageDriverName": "solidfire-san",
    "Endpoint": "https://admin:admin@192.168.160.3/json-rpc/8.0",
    "SVIP": "10.0.0.7:3260",
    "TenantName": "docker",
    "InitiatorIFace": "default",
    "Types": [
        {
            "Type": "Bronze",
            "Qos": {
                "minIOPS": 1000,
                "maxIOPS": 2000,
                "burstIOPS": 4000
            }
        },
        {
            "Type": "Silver",
            "Qos": {
                "minIOPS": 4000,
                "maxIOPS": 6000,
                "burstIOPS": 8000
            }
        },
        {
            "Type": "Gold",
            "Qos": {
                "minIOPS": 6000,
                "maxIOPS": 8000,
                "burstIOPS": 10000
            }
        }
    ]
}
----

== Cloud Volumes Service on Google Cloud Platform configuration

Astra Trident can create Cloud Volumes Service volumes in one of two link:https://cloud.google.com/architecture/partners/netapp-cloud-volumes/service-types[service types^]:

* *CVS-Performance*: The default Astra Trident service type. This performance-optimized service type is best suited for production workloads that value performance. The CVS-Performance service type is a hardware option supporting volumes with a minimum 100 GiB size. You can choose one of link:https://cloud.google.com/architecture/partners/netapp-cloud-volumes/service-levels#service_levels_for_the_cvs-performance_service_type[three  service levels^]: 

** `standard`
** `premium`
** `extreme`

* *CVS*: The CVS service type provides high zonal availability with limited to moderate performance levels. The CVS service type is a software option that uses storage pools to support volumes as small as 1 GiB. The storage pool can contain up to 50 volumes where all volumes share the capacity and performance of the pool. You can choose one of link:https://cloud.google.com/architecture/partners/netapp-cloud-volumes/service-levels#service_levels_for_the_cvs_service_type[two service levels^]: 

** `standardsw`
** `zoneredundantstandardsw`

=== Backend configuration options
Each backend provisions volumes in a single Google Cloud region. To create volumes in other regions, you can define additional backends. 

[%header,cols=3*]
|===
|Option
|Description
|Example

|`apiRegion`
|The Google Cloud region where Astra Trident creates Cloud Volumes Service volumes. When creating cross-region Kubernetes clusters, volumes created in an `apiRegion` can be used in workloads scheduled on nodes across multiple Google Cloud regions. 

Cross-region traffic incurs an additional cost.
|“us-west2”

|`projectNumber`
|Google Cloud account project number. The value is found on the Google Cloud portal home page. 
|“123456789012”

|`hostProjectNumber`
|Required if using a shared VPC network. In this scenario, `projectNumber` is the service project, and `hostProjectNumber` is the host project.
|“098765432109”

|`apiKey`
|API key for the Google Cloud service account with the `netappcloudvolumes.admin` role. 

It includes the JSON-formatted contents of a Google Cloud service account's private key file (copied verbatim into the backend configuration file). 
|(contents of the private key file)

|`apiRegion` |The Google Cloud region where Astra Trident creates Cloud Volumes Service volumes. When creating cross-region Kubernetes clusters, volumes created in an `apiRegion` can be used in workloads scheduled on nodes across multiple Google Cloud regions. 

Cross-region traffic incurs an additional cost.|

|`secretKey`
|CVS account secret key (required). Can be found in the CVS web portal in Account settings > API access.
|“default”

|`proxyURL`
|Proxy URL if proxy server required to connect to CVS account. The proxy server can either be an HTTP proxy or an HTTPS proxy. 

For an HTTPS proxy, certificate validation is skipped to allow the usage of self-signed certificates in the proxy server. 

Proxy servers with authentication enabled are not supported. 
|“http://proxy-server-hostname/”

|`nfsMountOptions`
|NFS mount options; defaults to “-o nfsvers=3”
|“nfsvers=3,proto=tcp,timeo=600”

| `serviceLevel` 
|The CVS or CVS-Performance service level for new volumes. 

CVS values are `standardsw` or `zoneredundantstandardsw`. 

CVS-Performance values are `standard`, `premium`, or `extreme`. 
| CVS default is "standardsw". 

CVS-Performance default is "standard".

|`network`
|Google Cloud network used for Cloud Volumes Service volumes.
|“default”

|===

=== Volume provisioning options

You can control default volume provisioning in the `defaults` section of the configuration file. 

[cols=",,",options="header",]
|===
|Parameter |Description |Default
|`exportRule` |The export rules for new volumes. Must be a comma-separated list of any combination of IPv4 addresses or IPv4 subnets in CIDR notation. |"0.0.0.0/0"
|`snapshotDir` |Access to the `.snapshot` directory | "false"
|`snapshotReserve` |Percentage of volume reserved for snapshots |"" (accept CVS default of 0)
|`size` |The size of new volumes. 

The minimum volume size for CVS service type is 1 GiB. 

The minimum size for CVS-Performance service type is 100 GiB. |CVS-Performance service type defaults to "100GiB". 

CVS service type does not set a default but requires a 1 GiB minimum.
|===

=== Example Cloud Volumes Service on Google Cloud configuration

----
{
    "version": 1,
    "storageDriverName": "gcp-cvs",
    "projectNumber": "012345678901",
    "apiRegion": "us-west2",
    "apiKey": {
        "type": "service_account",
        "project_id": "my-gcp-project",
        "private_key_id": "1234567890123456789012345678901234567890",
        "private_key": "-----BEGIN PRIVATE KEY-----\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nznHczZsrrtHisIsAbOguSaPIKeyAZNchRAGzlzZE4jK3bl/qp8B4Kws8zX5ojY9m\nXsYg6gyxy4zq7OlwWgLwGa==\n-----END PRIVATE KEY-----\n",
        "client_email": "cloudvolumes-admin-sa@my-gcp-project.iam.gserviceaccount.com",
        "client_id": "123456789012345678901",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/cloudvolumes-admin-sa%40my-gcp-project.iam.gserviceaccount.com"
    },
    "proxyURL": "http://proxy-server-hostname/"
}
----

== Azure NetApp Files configuration

To configure and use an https://azure.microsoft.com/en-us/services/netapp/[Azure NetApp Files^] backend, you will need the following:

* `subscriptionID` from an Azure subscription with Azure NetApp Files enabled
* `tenantID`, `clientID`, and `clientSecret` from an https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal[App Registration^] in Azure Active Directory with sufficient permissions to the Azure NetApp Files service
* Azure location that contains at least one https://docs.microsoft.com/en-us/azure/azure-netapp-files/azure-netapp-files-delegate-subnet[delegated subnet^]

TIP: If you’re using Azure NetApp Files for the first time or in a new location, some initial configuration is required that the https://docs.microsoft.com/en-us/azure/azure-netapp-files/azure-netapp-files-quickstart-set-up-account-create-volumes?tabs=azure-portal[quickstart guide^] will walk you through.

NOTE: Astra Trident 21.04.0 and earlier do not support Manual QoS capacity pools.

[%header,cols=3*]
|===
|Option
|Description
|Default

|`version`
a|Always 1
a|

|`storageDriverName`
a|“azure-netapp-files”
a|

|`backendName`
a|Custom name for the storage backend
a|Driver name + “_” + random characters

|`subscriptionID`
a|The subscription ID from your Azure subscription
a|

|`tenantID`
a|The tenant ID from an App Registration
a|

|`clientID`
a|The client ID from an App Registration
a|

|`clientSecret`
a|The client secret from an App Registration
a|

|`serviceLevel`
a|One of “Standard”, “Premium” or “Ultra”
a|“” (random)

|`location`
a|Name of the Azure location new volumes will be created in
a|“” (random)

|`virtualNetwork`
a|Name of a virtual network with a delegated subnet
a|“” (random)

|`subnet`
a|Name of a subnet delegated to `Microsoft.Netapp/volumes`
a|“” (random)

|`nfsMountOptions`
a|Fine-grained control of NFS mount options
a|“-o nfsvers=3”

|`limitVolumeSize`
a|Fail provisioning if requested volume size is above this value
a|“” (not enforced by default)

|===

NOTE: The Azure NetApp Files service does not support volumes less than 100 GB in size. To make it easier to deploy applications, Trident automatically creates 100 GB volumes if a smaller volume is requested.

You can control how each volume is provisioned by default using these options in a special section of the configuration.

[%header,cols=3*]
|===
|Option
|Description
|Default

|`exportRule`
a|The export rule(s) for new volumes. Must be a comma-separated list of any combination of IPv4 addresses or IPv4 subnets in CIDR notation.
a|“0.0.0.0/0”

|`snapshotDir`
a|Controls visibility of the `.snapshot` directory
a|“false”

|`size`
a|The default size of new volumes
a|“100G”

|===

=== Example Azure NetApp Files configurations

*Example 1: Minimal backend configuration for azure-netapp-files*

This is the absolute minimum backend configuration. With this configuration, Trident will discover all of your NetApp accounts, capacity pools, and subnets delegated to ANF in every location worldwide, and place new volumes on one of them randomly.

This configuration is useful when you’re just getting started with ANF and trying things out, but in practice you’re going to want to provide additional scoping for the volumes you provision to make sure that they have the characteristics you want and end up on a network that’s close to the compute that’s using it. See the subsequent examples for more details.

----
{
    "version": 1,
    "storageDriverName": "azure-netapp-files",
    "subscriptionID": "9f87c765-4774-fake-ae98-a721add45451",
    "tenantID": "68e4f836-edc1-fake-bff9-b2d865ee56cf",
    "clientID": "dd043f63-bf8e-fake-8076-8de91e5713aa",
    "clientSecret": "SECRET"
}
----

*Example 2: Single location and specific service level for azure-netapp-files*

This backend configuration places volumes in Azure’s “eastus” location in a “Premium” capacity pool. Trident automatically discovers all of the subnets delegated to ANF in that location and will place a new volume on one of them randomly.

----
{
    "version": 1,
    "storageDriverName": "azure-netapp-files",
    "subscriptionID": "9f87c765-4774-fake-ae98-a721add45451",
    "tenantID": "68e4f836-edc1-fake-bff9-b2d865ee56cf",
    "clientID": "dd043f63-bf8e-fake-8076-8de91e5713aa",
    "clientSecret": "SECRET",
    "location": "eastus",
    "serviceLevel": "Premium"
}
----

*Example 3: Advanced configuration for azure-netapp-files*

This backend configuration further reduces the scope of volume placement to a single subnet, and also modifies some volume provisioning defaults.

----
{
    "version": 1,
    "storageDriverName": "azure-netapp-files",
    "subscriptionID": "9f87c765-4774-fake-ae98-a721add45451",
    "tenantID": "68e4f836-edc1-fake-bff9-b2d865ee56cf",
    "clientID": "dd043f63-bf8e-fake-8076-8de91e5713aa",
    "clientSecret": "SECRET",
    "location": "eastus",
    "serviceLevel": "Premium",
    "virtualNetwork": "my-virtual-network",
    "subnet": "my-subnet",
    "nfsMountOptions": "nfsvers=3,proto=tcp,timeo=600",
    "limitVolumeSize": "500Gi",
    "defaults": {
        "exportRule": "10.0.0.0/24,10.0.1.0/24,10.0.2.100",
        "size": "200Gi"
    }
}
----

*Example 4: Virtual storage pools with azure-netapp-files*

This backend configuration defines multiple link:../trident-concepts/virtual-storage-pool.html[pools of storage^] in a single file. This is useful when you have multiple capacity pools supporting different service levels and you want to create storage classes in Kubernetes that represent those.

This is just scratching the surface of the power of virtual storage pools and their labels.

----
{
    "version": 1,
    "storageDriverName": "azure-netapp-files",
    "subscriptionID": "9f87c765-4774-fake-ae98-a721add45451",
    "tenantID": "68e4f836-edc1-fake-bff9-b2d865ee56cf",
    "clientID": "dd043f63-bf8e-fake-8076-8de91e5713aa",
    "clientSecret": "SECRET",
    "nfsMountOptions": "nfsvers=3,proto=tcp,timeo=600",
    "labels": {
        "cloud": "azure"
    },
    "location": "eastus",

    "storage": [
        {
            "labels": {
                "performance": "gold"
            },
            "serviceLevel": "Ultra"
        },
        {
            "labels": {
                "performance": "silver"
            },
            "serviceLevel": "Premium"
        },
        {
            "labels": {
                "performance": "bronze"
            },
            "serviceLevel": "Standard",
        }
    ]
}
----
